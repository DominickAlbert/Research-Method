{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.utils import shuffle\n",
    "from nlpaug.augmenter.word import SynonymAug\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"en_dataset_with_stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = [\"directness\",\"HITId\",\"annotator_sentiment\",\"target\",\"group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x):\n",
    "    if \"hateful\" in x:\n",
    "        return 1\n",
    "    elif \"normal\" in x:\n",
    "        return 0\n",
    "    else:\n",
    "        return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"sentiment\"] = dataset[\"sentiment\"].apply(lambda x : label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns = {\"sentiment\" : \"Hate_Speech\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(dataset[dataset[\"Hate_Speech\"] == -2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Hate_Speech\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9824\\69068997.py:15: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))','', tweet)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "punch = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "def data_preprocessing(tweet):\n",
    "    tweet = re.sub(r'&gt', '', tweet)\n",
    "    tweet = re.sub(r'\\b\\\\x\\S\\S', '',tweet)\n",
    "    tweet = re.sub(r'\\\\u\\S*', '', tweet)\n",
    "    tweet = re.sub(r'\\B\\\\x\\S+', '',tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'ð', '', tweet)\n",
    "    tweet =\"\".join([i for i in tweet if i not in punch])\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub('\\n','',tweet)\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))','', tweet)\n",
    "    tweet = re.sub('  +', '', tweet)\n",
    "    tweet = re.sub(r'pic.twitter.com.[\\w]+', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    tweet = re.sub(r'\\burl', '', tweet)\n",
    "    tweet = re.sub(r'@', '', tweet)\n",
    "    tweet = re.sub(r'\\A', '', tweet)\n",
    "    tweet = re.sub('user','', tweet)\n",
    "    # tweet = re.sub(r'\\s', '', tweet)\n",
    "    if tweet.startswith(\"rt user\"): return False\n",
    "    return tweet\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "\n",
    "\n",
    "    if None in corrected_text:\n",
    "        return text      \n",
    "    \n",
    "    return \" \".join(corrected_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tweet'] = dataset['tweet'].apply(data_preprocessing)\n",
    "dataset['tweet'] = dataset['tweet'].apply(correct_spellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing.to_csv('ready_to_translate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset that is ready to translate\n",
    "import pandas as pd\n",
    "englishDS = pd.read_csv(\"ready_to_translate.csv\",index_col= 0)\n",
    "englishDS = englishDS.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hate_Speech\n",
       "1    1278\n",
       "0     974\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishDS['Hate_Speech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP AUG to balance the dataset using wordnet\n",
    "\n",
    "def augment_text(df,samples=304,pr=0.2):\n",
    "    aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "    new_text=[]\n",
    "\n",
    "    df_n=df[df[\"Hate_Speech\"]==0].reset_index(drop=True)\n",
    "\n",
    "    for i in np.random.randint(0,len(df_n),samples):\n",
    "\n",
    "            text = df_n.iloc[i]['tweet']\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "    ## dataframe\n",
    "    new=pd.DataFrame({'tweet':new_text,'Hate_Speech':0})\n",
    "\n",
    "\n",
    "    df = pd.concat([df, new],axis=0).reset_index(drop=True)\n",
    "    df = shuffle(df)\n",
    "    return df\n",
    "\n",
    "train = augment_text(englishDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hate_Speech\n",
       "0    1278\n",
       "1    1278\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Hate_Speech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset that has been translated\n",
    "\n",
    "IDT = pd.read_csv(\"IndonesianDatasetWOPP.csv\")\n",
    "IDT = IDT.drop(columns=\"Unnamed: 0\")\n",
    "IDT = IDT.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords\n",
    "\n",
    "stop_words = pd.read_json('stopwords-id.json')\n",
    "stop_words.columns = ['Words']\n",
    "stop_words['Words'].head()\n",
    "stopwords = stop_words['Words'].tolist()\n",
    "def remove_stopwords(tweet):\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    filtered_tweets = [w for w in tweet_tokens if not w in stopwords]\n",
    "    return \" \".join(filtered_tweets)\n",
    "\n",
    "IDT.translated_tweet = IDT['translated_tweet'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [dia, lucu, lapisan, gulanya, standar, suka, m...\n",
      "1    [benar, benar, benar, cauline, hansom, apa, pu...\n",
      "2                  [anda, menghormati, negro, bendera]\n",
      "3                     [sh, wanita, benar, terbelakang]\n",
      "4       [pertanyaanmu, faggot, homgote, sialan, fagot]\n",
      "5                            [malam, buruk, mongoloid]\n",
      "6    [saya, berharap, salah, memerintah, dunia, trump]\n",
      "7                               [susan, anda, berasal]\n",
      "8                                [kami, benar, vagina]\n",
      "9                              [beri, memanggil, spic]\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the tweets\n",
    "\n",
    "tokenized_data = IDT\n",
    "tokenized_data['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in tokenized_data['translated_tweet']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the word2vec model\n",
    "\n",
    "size = 1000\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "word2vec_model_file = 'C:\\\\Users\\\\User\\\\Documents\\\\Pythobn\\\\RM\\\\' + 'word2vec_' + str(size) + '.model'\n",
    "start_time = time.time()\n",
    "tokenized_tweets = pd.Series(tokenized_data['tokenized_text']).values\n",
    "w2v_model = Word2Vec(tokenized_tweets, min_count=min_count, vector_size=size, workers=workers, window=window, sg=sg)\n",
    "print(f\"Time taken to train word2Vec model: {time.time() - start_time}\")\n",
    "w2v_model.save(word2vec_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the word2vec model\n",
    "\n",
    "size = 1000\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "word2vec_model_file = 'C:\\\\Users\\\\User\\\\Documents\\\\Pythobn\\\\RM\\\\' + 'word2vec_' + str(size) + '.model'\n",
    "sg_w2v_model = Word2Vec.load(word2vec_model_file)\n",
    "vocab = sg_w2v_model.wv.key_to_index\n",
    "print(sg_w2v_model.wv.get_vector(vocab['indonesia']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [sg_w2v_model.wv[word] for word in words if word in sg_w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(1000)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset that has been translated and preprocessed\n",
    "\n",
    "df = pd.read_csv('translated_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hate_Speech\n",
       "1    1276\n",
       "0    1273\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hate_Speech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['translated_tweet'], df['Hate_Speech'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([vectorize(str(sentence)) for sentence in X_train])\n",
    "X_test = np.array([vectorize(str(sentence)) for sentence in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.59       256\n",
      "           1       0.57      0.50      0.53       254\n",
      "\n",
      "    accuracy                           0.56       510\n",
      "   macro avg       0.56      0.56      0.56       510\n",
      "weighted avg       0.56      0.56      0.56       510\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58      1017\n",
      "           1       0.56      0.50      0.53      1022\n",
      "\n",
      "    accuracy                           0.55      2039\n",
      "   macro avg       0.55      0.55      0.55      2039\n",
      "weighted avg       0.55      0.55      0.55      2039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(random_state=42)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_train, clf_lr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.56       256\n",
      "           1       0.53      0.48      0.51       254\n",
      "\n",
      "    accuracy                           0.53       510\n",
      "   macro avg       0.53      0.53      0.53       510\n",
      "weighted avg       0.53      0.53      0.53       510\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      1017\n",
      "           1       0.97      0.93      0.95      1022\n",
      "\n",
      "    accuracy                           0.95      2039\n",
      "   macro avg       0.95      0.95      0.95      2039\n",
      "weighted avg       0.95      0.95      0.95      2039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state=42)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "y_pred = clf_dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_train, clf_dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.64       256\n",
      "           1       0.55      0.16      0.25       254\n",
      "\n",
      "    accuracy                           0.52       510\n",
      "   macro avg       0.53      0.51      0.45       510\n",
      "weighted avg       0.53      0.52      0.45       510\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.85      0.65      1017\n",
      "           1       0.59      0.22      0.32      1022\n",
      "\n",
      "    accuracy                           0.53      2039\n",
      "   macro avg       0.56      0.53      0.48      2039\n",
      "weighted avg       0.56      0.53      0.48      2039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(kernel='linear',random_state=42)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_train, clf_svm.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       256\n",
      "           1       0.56      0.65      0.60       254\n",
      "\n",
      "    accuracy                           0.57       510\n",
      "   macro avg       0.58      0.57      0.57       510\n",
      "weighted avg       0.58      0.57      0.57       510\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73      1017\n",
      "           1       0.72      0.80      0.76      1022\n",
      "\n",
      "    accuracy                           0.75      2039\n",
      "   macro avg       0.75      0.75      0.75      2039\n",
      "weighted avg       0.75      0.75      0.75      2039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_train, clf_knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       256\n",
      "           1       0.56      0.46      0.51       254\n",
      "\n",
      "    accuracy                           0.55       510\n",
      "   macro avg       0.56      0.55      0.55       510\n",
      "weighted avg       0.56      0.55      0.55       510\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      1017\n",
      "           1       0.97      0.93      0.95      1022\n",
      "\n",
      "    accuracy                           0.95      2039\n",
      "   macro avg       0.95      0.95      0.95      2039\n",
      "weighted avg       0.95      0.95      0.95      2039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42, n_jobs=200)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_train, clf_rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation with the other model that has been trained with the Originally Indonesian dataset.\n",
    "\n",
    "IndoDT = pd.read_csv('cleaned_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = IndoDT[IndoDT['Hate_Speech'] == 0].sample(500,random_state=42)\n",
    "pos = IndoDT[IndoDT['Hate_Speech'] == 1].sample(500,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([neg, pos])\n",
    "test_df = shuffle(test_df)\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 998 entries, 9106 to 7779\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Tweet           998 non-null    object\n",
      " 1   Hate_Speech     998 non-null    int64 \n",
      " 2   tokenized_text  998 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['Tweet']\n",
    "X_test = np.array([vectorize(str(sentence)) for sentence in X_test])\n",
    "y_test = test_df['Hate_Speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65       498\n",
      "           1       0.56      0.09      0.15       500\n",
      "\n",
      "    accuracy                           0.51       998\n",
      "   macro avg       0.53      0.51      0.40       998\n",
      "weighted avg       0.53      0.51      0.40       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55       498\n",
      "           1       0.55      0.53      0.54       500\n",
      "\n",
      "    accuracy                           0.55       998\n",
      "   macro avg       0.55      0.55      0.55       998\n",
      "weighted avg       0.55      0.55      0.55       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66       498\n",
      "           1       0.58      0.03      0.05       500\n",
      "\n",
      "    accuracy                           0.50       998\n",
      "   macro avg       0.54      0.50      0.36       998\n",
      "weighted avg       0.54      0.50      0.36       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52       498\n",
      "           1       0.48      0.40      0.44       500\n",
      "\n",
      "    accuracy                           0.48       998\n",
      "   macro avg       0.48      0.48      0.48       998\n",
      "weighted avg       0.48      0.48      0.48       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.82      0.63       498\n",
      "           1       0.55      0.21      0.31       500\n",
      "\n",
      "    accuracy                           0.52       998\n",
      "   macro avg       0.53      0.52      0.47       998\n",
      "weighted avg       0.53      0.52      0.47       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
